{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>57000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>76000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender   Age  EstimatedSalary Purchased\n",
       "0  15624510    Male  19.0            19000        No\n",
       "1  15810944    Male  35.0            20000        No\n",
       "2  15668575  Female   NaN            43000        No\n",
       "3  15603246  Female  27.0            57000        No\n",
       "4  15804002    Male  19.0            76000        No"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv('Social_Network_Ads.csv') \n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000e+02</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.569154e+07</td>\n",
       "      <td>37.684211</td>\n",
       "      <td>69742.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.165832e+04</td>\n",
       "      <td>10.479726</td>\n",
       "      <td>34096.960282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.556669e+07</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.562676e+07</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>43000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.569434e+07</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.575036e+07</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>88000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.581524e+07</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User ID         Age  EstimatedSalary\n",
       "count  4.000000e+02  399.000000       400.000000\n",
       "mean   1.569154e+07   37.684211     69742.500000\n",
       "std    7.165832e+04   10.479726     34096.960282\n",
       "min    1.556669e+07   18.000000     15000.000000\n",
       "25%    1.562676e+07   30.000000     43000.000000\n",
       "50%    1.569434e+07   37.000000     70000.000000\n",
       "75%    1.575036e+07   46.000000     88000.000000\n",
       "max    1.581524e+07   60.000000    150000.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:, 1:-1].values  # get all row data expect from the first and last column\n",
    "y = dataset.iloc[:, -1].values  # get the last column depentant variable data for all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Male' 19.0 19000]\n",
      " ['Male' 35.0 20000]\n",
      " ['Female' nan 43000]\n",
      " ['Female' 27.0 57000]\n",
      " ['Male' 19.0 76000]\n",
      " ['Male' 27.0 58000]\n",
      " ['Female' 27.0 84000]\n",
      " ['Female' 32.0 150000]\n",
      " ['Male' 25.0 33000]\n",
      " ['Female' 35.0 65000]]\n"
     ]
    }
   ],
   "source": [
    "print(x[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'No' 'No' 'No' 'No' 'No' 'No' 'Yes' 'No' 'No']\n"
     ]
    }
   ],
   "source": [
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing missing data with mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "imputer = SimpleImputer(missing_values=np.nan,strategy='mean') \n",
    "# fit method will look for missing values and calulate mean for 1st and 2nd columns \n",
    "imputer.fit(x[:,1:3]) \n",
    "# transform method will replace missign value with calulated value in 1st(age) and 2nd(salary) columns\n",
    "x[:,1:3]=imputer.transform(x[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Male' 19.0 19000.0]\n",
      " ['Male' 35.0 20000.0]\n",
      " ['Female' 37.68421052631579 43000.0]\n",
      " ['Female' 27.0 57000.0]\n",
      " ['Male' 19.0 76000.0]\n",
      " ['Male' 27.0 58000.0]\n",
      " ['Female' 27.0 84000.0]\n",
      " ['Female' 32.0 150000.0]\n",
      " ['Male' 25.0 33000.0]\n",
      " ['Female' 35.0 65000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding turn country columns to 3(as there are 3 countires).It created binary vector for each country so that there is no order between these countries. Final output will be - France vector 1,0,0 Spain 0,1,0 and Germany 0,0,1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding independent variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 19.0 19000.0]\n",
      " [0.0 1.0 35.0 20000.0]\n",
      " [1.0 0.0 37.68421052631579 43000.0]\n",
      " [1.0 0.0 27.0 57000.0]\n",
      " [0.0 1.0 19.0 76000.0]\n",
      " [0.0 1.0 27.0 58000.0]\n",
      " [1.0 0.0 27.0 84000.0]\n",
      " [1.0 0.0 32.0 150000.0]\n",
      " [0.0 1.0 25.0 33000.0]\n",
      " [1.0 0.0 35.0 65000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],remainder='passthrough') # Apply tranformation to change country to binary vector  Remainder keep age and salary \n",
    "x = np.array(ct.fit_transform(x)) #fitting and transforming together and force output to be numpy array \n",
    "print(x[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encoding dependent variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# use LabelEncoder to replace purchased (dependent variable) with 0 and 1 \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "y= le.fit_transform(y)\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset into training and test set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state = 0) # func returns train and test data. It takes dataset and then split size test_size =0.3 means 30% data is for test and rest for training and random_state \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 26.0 15000.0]\n",
      " [0.0 1.0 60.0 102000.0]\n",
      " [1.0 0.0 38.0 112000.0]\n",
      " [0.0 1.0 40.0 107000.0]\n",
      " [1.0 0.0 42.0 53000.0]\n",
      " [0.0 1.0 35.0 59000.0]\n",
      " [0.0 1.0 48.0 41000.0]\n",
      " [1.0 0.0 48.0 134000.0]\n",
      " [1.0 0.0 38.0 113000.0]\n",
      " [0.0 1.0 29.0 148000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 30.0 87000.0]\n",
      " [1.0 0.0 38.0 50000.0]\n",
      " [0.0 1.0 35.0 75000.0]\n",
      " [1.0 0.0 30.0 79000.0]\n",
      " [1.0 0.0 35.0 50000.0]\n",
      " [0.0 1.0 27.0 20000.0]\n",
      " [1.0 0.0 31.0 15000.0]\n",
      " [0.0 1.0 36.0 144000.0]\n",
      " [1.0 0.0 18.0 68000.0]\n",
      " [0.0 1.0 47.0 43000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that not all models need Feature scaling to be applied. Apply feature scaling after splitting the dataset. Test set is supposed to be new data set. Feature scaling will get mean and median of the data so its better to apply this after splitting data so to avoid data leakage   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Main two feature scaling techniques are standardisation and normalisation\n",
    "\n",
    " Xstan =(x - mean(x))/(standard deviation(x)) > The resulting output value will be between -3 and +3\n",
    " Xnorm =(x - min(x))/(max(x) - min(x)) > The resulting output value will be between 0 and 1\n",
    "\n",
    "Normalisation is recommended to be used for normal distribution while standardisation works well all the time. So it is better to go for standardisation.\n",
    "We do not need to apply feature scaling on dummy variables as they are already encoding to 0 or 1 or binary vector so nothing extra to be done by standardisation which will convert the value to between -3 & 3. Also it will make us loose the intepretation of the dummy variable(here country and purchased col) i.e which country correspond to which after standardisation. Many say that applying standardisation on dummy variable may increase model performance but I have never seen anything which proves it.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 26.0 -1.5849702974485314]\n",
      " [0.0 1.0 60.0 0.9309867236544418]\n",
      " [1.0 0.0 38.0 1.2201771858501858]\n",
      " [0.0 1.0 40.0 1.0755819547523138]\n",
      " [1.0 0.0 42.0 -0.486046541104704]\n",
      " [0.0 1.0 35.0 -0.3125322637872576]\n",
      " [0.0 1.0 48.0 -0.8330750957395968]\n",
      " [1.0 0.0 48.0 1.8563962026808227]\n",
      " [1.0 0.0 38.0 1.2490962320697603]\n",
      " [0.0 1.0 29.0 2.261262849754864]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# take all columns from age. fit computes mean and median of each value. transform apply formula to tranform them to Xstand\n",
    "x_train[:,3:] = scaler.fit_transform(x_train[:,3:]) \n",
    "#Need to apply the same scaler on both train and test set to get same transformation \n",
    "x_test[:,3:] = scaler.transform(x_test[:,3:])\n",
    "print(x_train[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 30.0 0.4972010303608257]\n",
      " [1.0 0.0 38.0 -0.5728036797634273]\n",
      " [0.0 1.0 35.0 0.15017247572593284]\n",
      " [1.0 0.0 30.0 0.26584866060423046]\n",
      " [1.0 0.0 35.0 -0.5728036797634273]\n",
      " [0.0 1.0 27.0 -1.4403750663506594]\n",
      " [1.0 0.0 31.0 -1.5849702974485314]\n",
      " [0.0 1.0 36.0 2.1455866648765665]\n",
      " [1.0 0.0 18.0 -0.05226084781108797]\n",
      " [0.0 1.0 47.0 -0.7752370033004481]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, random_state=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "regressor = LogisticRegression(penalty = 'l2', C = 1000, random_state=0)\n",
    "regressor.fit(x_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the test set results\n",
    "y_pred = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5183698672429762"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, confusion_matrix, classification_report\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10833333333333334"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10833333333333334"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74  5]\n",
      " [ 8 33]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        79\n",
      "           1       0.87      0.80      0.84        41\n",
      "\n",
      "    accuracy                           0.89       120\n",
      "   macro avg       0.89      0.87      0.88       120\n",
      "weighted avg       0.89      0.89      0.89       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
